---
title: "Assignment 3"
author: "Laurits Lyngbaek"
date: "2025-03-18"
output: html_document
---
**Load Packages**
```{r}
pacman::p_load(tidyverse, # Data Wrangling and Plotting
               tidybayes, # Transforming posterior draws to tibbles
               cmdstanr,  # Package for compiling Stan script from Rscript into C++  
               posterior,
               patchwork)
```

# Clean Data
```{r}
pre <- readr::read_csv(file = "Data/preCorona.csv")
during <- readr::read_csv(file = "Data/duringCorona.csv") 
```

```{r}
# Beta-binomial model for Bayesian integration in the marble task
#
# This function implements a Bayesian integration model for combining direct and social evidence
# about the proportion of blue marbles in a jar. It uses the beta-binomial model, which is
# particularly suitable for reasoning about proportions.
#
# Parameters:
#   alpha_prior: Prior alpha parameter (conceptually: prior counts of x + 1)
#   beta_prior: Prior beta parameter (conceptually: prior counts of y + 1)
#   alpha_likelihood: Likelihood from direct evidence (counts of x, seen by you)
#   total: Total direct evidence (x + y)
#   alpha_likelihood_social: Likelihood from social evidence (counts of x, seen by other)
#   total_social: Effective total marbles from social evidence (x+y)
#
# Returns:
#   List with posterior parameters and statistics for decision-making
betaBinomialModel <- function(alpha_prior, beta_prior, alpha_likelihood, total, alpha_likelihood_social, total_social) {
  # Calculate red marbles for each source
  beta_likelihood <- total - alpha_likelihood  # Number of red marbles in direct evidence
  beta_likelihood_social <- total_social - alpha_likelihood_social # Inferred number of red marbles from social evidence
  
  # The key insight of Bayesian integration: simply add up all evidence counts
  # This automatically gives more weight to sources with more data
  alpha_post <- alpha_prior + alpha_likelihood + alpha_likelihood_social  # Posterior alpha (total blues + prior)
  beta_post <- beta_prior + beta_likelihood + beta_likelihood_social      # Posterior beta (total reds + prior)
  
  # Calculate posterior statistics
  expected_rate <- alpha_post / (alpha_post + beta_post)  # Mean of beta distribution
  
  # Variance has a simple formula for beta distributions
  # Lower variance = higher confidence in our estimate
  variance <- (alpha_post * beta_post) / 
             ((alpha_post + beta_post)^2 * (alpha_post + beta_post + 1))
  
  # Calculate 95% credible interval using beta quantile functions
  # This gives us bounds within which we believe the true proportion lies
  ci_lower <- qbeta(0.025, alpha_post, beta_post)
  ci_upper <- qbeta(0.975, alpha_post, beta_post)
  
  # Calculate confidence based on variance
  # Higher variance = lower confidence; transform to 0-1 scale
  confidence <- 1 - (2 * sqrt(variance))
  confidence <- max(0, min(1, confidence))  # Bound between 0 and 1
  
  # Make decision based on whether expected rate exceeds 0.5
  # If P(blue) > 0.5, choose blue; otherwise choose red
  choice <- rbinom(1, size = total,prob=expected_rate )
  
  # Return all calculated parameters in a structured list
  return(list(
    alpha_post = alpha_post,
    beta_post = beta_post,
    expected_rate = expected_rate,
    variance = variance,
    ci_lower = ci_lower,
    ci_upper = ci_upper,
    confidence = confidence,
    choice = choice
  ))
}
```

```{r}
# Set total counts for direct and social evidence
total <- 8  # Total evidence units in direct evidence
total_social <- 8  # Total evidence units in social evidence

# Create all possible combinations of direct and social evidence
scenarios <- expand_grid(
  alpha_likelihood = seq(0, 8, 1),  # Direct evidence: 0 to 8 blue marbles
  alpha_likelihood_social = seq(1, 8, 2)   # Social evidence: 0, 2, 4, 6, 8 (confidence levels)
) %>% mutate(
  beta_likelihood = total - alpha_likelihood,  # Calculate red marbles for direct evidence
  beta_likelihood_social = total_social - alpha_likelihood_social   # Calculate implied red marbles for social evidence
)

# Process all scenarios to generate summary statistics
sim_data <- map_dfr(1:nrow(scenarios), function(i) {
  # Extract scenario parameters
  alpha_likelihood <- scenarios$alpha_likelihood[i]
  beta_likelihood <- scenarios$beta_likelihood[i]
  alpha_likelihood_social <- scenarios$alpha_likelihood_social[i]
  beta_likelihood_social <- scenarios$beta_likelihood_social[i]
  
  # Calculate Bayesian integration using our model
  result <- betaBinomialModel(10, 1, alpha_likelihood, total, alpha_likelihood_social, total_social)
  
  # Return summary data for this scenario
  tibble(
    alpha_likelihood = alpha_likelihood,
    beta_likelihood = beta_likelihood,
    alpha_likelihood_social = alpha_likelihood_social,
    beta_likelihood_social = beta_likelihood_social,
    expected_rate = result$expected_rate,
    variance = result$variance,
    ci_lower = result$ci_lower,
    ci_upper = result$ci_upper,
    choice = result$choice,
    confidence = result$confidence
  )
})



# Convert social evidence to meaningful labels for better visualization
sim_data$trustability <- factor(sim_data$beta_likelihood_social,
                                 levels = c(1, 3, 5, 7),
                                 labels = c("Very Low", "Low", "Medium", "High"))

# Function to prepare data for Stan
prepare_stan_data <- function(df) {
  list(
    N = nrow(df),
    choice = df$choice,
    alpha_likelihood = df$alpha_likelihood,
    total = df$alpha_likelihood+df$beta_likelihood,
    alpha_likelihood_social = df$alpha_likelihood_social,
    total_social = df$alpha_likelihood_social+df$beta_likelihood_social
  )
}

# Prepare Data
stan_sim_data <- prepare_stan_data(sim_data)
```


```{r}
# Compile models
mod_simple <- cmdstan_model(stan_file = "Bayes.stan", cpp_options = list(stan_threads = TRUE))


# Fit simple model to each agent's data
fit_simple_balanced <- mod_simple$sample(
  data = stan_sim_data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 1,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 500  # Set to 500 or so to see progress
)

fit_simple_balanced

```






















#### Fitting the real data
```{r}
# Filter out rows where rating is 0
clean_pre_df <- pre %>%
  filter(FirstRating > 0,
         GroupRating > 0,
         SecondRating > 0)

# prepre for stan
stan_pre_data <- list(
  N = nrow(clean_pre_df),
  choice = clean_pre_df$SecondRating,
  alpha_likelihood = clean_pre_df$FirstRating,
  total = rep(8, nrow(clean_pre_df)),
  alpha_likelihood_social = clean_pre_df$GroupRating,
  total_social = rep(8, nrow(clean_pre_df))
)

```




```{r}
fit_simple_real <- mod_simple$sample(
  data = stan_pre_data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 1,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 500
)

```





```{r}
create_diagnostic_plots <- function(fit) {
  # Extract posterior draws
  draws <- as_draws_df(fit$draws())

  trace_plot1 <- ggplot(draws, aes(x = .iteration, y = alpha_prior, color = factor(.chain))) +
    geom_line(alpha = 0.7) +
    labs(title = "Trace Plot for alpha_prior",
         x = "Iteration",
         y = "alpha_prior",
         color = "Chain") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))

  trace_plot2 <- ggplot(draws, aes(x = .iteration, y = beta_prior, color = factor(.chain))) +
    geom_line(alpha = 0.7) +
    labs(title = "Trace Plot for beta_prior",
         x = "Iteration",
         y = "beta_prior",
         color = "Chain") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))

  # Combine using patchwork if available
  combined_trace_plot <- trace_plot1 / trace_plot2
  return(combined_trace_plot)
}

```


```{r}
create_diagnostic_plots(fit_simple_real)

```


### Prior-Posterior predictive checks
```{r}
library(dplyr)
plot_predictive_checks <- function(stan_fit,
                                   sim_results,
                                   model_name = "Simple",
                                   param_name = "prior_pred_choice"){
  # extract predicitve samples
  pred_samples <- stan_fit$draws(param_name, format="data.frame")
  
  #get number of samples and observations
  #n_samples <- nrow(pred_samples)
  #n_obs <- ncol(pred_samples) -3       # why 3?
  
  # conver to long fromat
  long_pred <- pred_samples %>% 
    dplyr::select(-.chain, -.iteration, -.draw) %>%
    pivot_longer(
      cols = everything(),
      names_to = "obs_id",
      values_to = "choice"
    ) %>%
    mutate(obs_id = parse_number(obs_id))
  
  # Join with the original simulation data to get evidence levels
  # First, add an observation ID to the simulation data
  sim_with_id <- sim_results %>%
    mutate(obs_id = row_number())
  
  # Join predictions with evidence levels
  long_pred_with_evidence <- long_pred %>%
    left_join(
      sim_with_id %>%
        dplyr::select(obs_id, alpha_likelihood, alpha_likelihood_social),
      by = "obs_id"
    )
  
    # Summarize proportion of 1s per evidence combination
  pred_summary <- long_pred_with_evidence %>%
    group_by(alpha_likelihood, alpha_likelihood_social) %>%
    summarize(
      # proportion = mean(choice, na.rm = TRUE), 
      # n = n(),  
      # se = sqrt((proportion * (1 - proportion)) / n),  # Binomial SE
      # lower = proportion - 1.96 * se,  
      # upper = proportion + 1.96 * se,
      proportion = mean(choice),
      lower = quantile(choice, 0.025),
      upper = quantile(choice, 0.975),
      .groups = "drop"
    )
  
  # Generate title based on parameter name
  title <- ifelse(param_name == "prior_pred_choice", 
                  paste0("Prior Predictive Check for ", model_name),
                  paste0("Posterior Predictive Check for ", model_name))

 # Create plot
ggplot(pred_summary, aes(x = alpha_likelihood, y = proportion, color =
factor(alpha_likelihood_social)), show.legend = FALSE) +
    geom_line(show.legend = FALSE) +
    geom_point(show.legend = FALSE) +
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = factor(alpha_likelihood_social)), alpha = 0.2, color = NA) +
    labs(
      title = title,
      x = "Direct Evidence (alpha_likelihood)",
      y = "Proportion of Choice",
      fill = "Social Evidence"
    ) +
    theme_minimal()
}

```


```{r}
# posterior simple
# posterior weighted
posterior_simple <- plot_predictive_checks(fit_simple_real, plot_data, "Simple", "posterior_pred_choice")
```

```{r}
posterior_simple
```





